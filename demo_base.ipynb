{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be54000d",
   "metadata": {},
   "source": [
    "# 版图电容预测基本模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e2696",
   "metadata": {},
   "source": [
    "## 参数解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f7d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "import argparse\n",
    "\n",
    "from config import *\n",
    "\n",
    "\n",
    "sys.argv = ['run.py']\n",
    "\n",
    "def str2bool(v):\n",
    "\tif v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "\t\treturn True\n",
    "\telif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "\t\treturn False\n",
    "\telse:\n",
    "\t\traise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dir_prj', type=str, default=dir_prj,\n",
    "\t\t\t\t\t\t\t\t\t\thelp='project directory')\n",
    "parser.add_argument('--seed', type=int, default=seed,\n",
    "\t\t\t\t\t\t\t\t\t\thelp='random seed')\n",
    "parser.add_argument('--pattern_nums', type=int, nargs='+', default=pattern_nums,\n",
    "\t\t\t\t\t\t\t\t\t\thelp='pattern nums')\n",
    "parser.add_argument('--thresh', type=int, nargs='+', default=thresh,\n",
    "\t\t\t\t\t\t\t\t\t\thelp='threshold')\n",
    "parser.add_argument('--num_process', type=int, default=num_process,\n",
    "\t\t\t\t\t\t\t\t\t\thelp='multiprocessing number')\n",
    "parser.add_argument('--n_components', type=int, default=n_components,\n",
    "\t\t\t\t\t\t\t\t\t\thelp='number of components for DDR')\n",
    "parser.add_argument('--disable_norm', action='store_true',\n",
    "\t\t\t\t\t\t\t\t\t\thelp='disable normalization')\n",
    "parser.add_argument('--disable_ddr', action='store_true',\n",
    "\t\t\t\t\t\t\t\t\t\thelp='disable dimensionality reduction')\n",
    "parser.add_argument('--use_ddr_pca', action='store_true',\n",
    "\t\t\t\t\t\t\t\t\t\thelp='use DDR PCA')\n",
    "parser.add_argument('--use_ddr_kpca', action='store_true',\n",
    "\t\t\t\t\t\t\t\t\t\thelp='use DDR KPCA')\n",
    "parser.add_argument('--use_ddr_var', action='store_true',\n",
    "\t\t\t\t\t\t\t\t\t\thelp='use DDR VAR')\n",
    "parser.add_argument('--use_ddr_ae', action='store_true',\t\n",
    "\t\t\t\t\t\t\t\t\t\thelp='use DDR AE')\n",
    "\n",
    "args = parser.parse_args()\n",
    "dir_prj = args.dir_prj\n",
    "seed = args.seed\n",
    "pattern_nums = args.pattern_nums\n",
    "thresh = args.thresh\n",
    "num_process = args.num_process\n",
    "n_components = args.n_components\n",
    "DISABLE_NORM = args.disable_norm\n",
    "DISABLE_DDR = args.disable_ddr\n",
    "USE_DDR_PCA = args.use_ddr_pca\n",
    "USE_DDR_KPCA = args.use_ddr_kpca\n",
    "USE_DDR_VAR = args.use_ddr_var\n",
    "USE_DDR_AE = args.use_ddr_ae\n",
    "USE_DDR = not DISABLE_DDR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020a79e",
   "metadata": {},
   "source": [
    "## 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363c999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f9f36",
   "metadata": {},
   "source": [
    "## 路径定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b906cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# log save path\n",
    "dir_logs = os.path.join(os.getcwd(), '../logs')\n",
    "if not os.path.exists(dir_logs):\n",
    "\tos.mkdir(dir_logs)\n",
    "\n",
    "# results save path\n",
    "dir_results = os.path.join(os.getcwd(), '../results')\n",
    "if not os.path.exists(dir_results):\n",
    "\tos.mkdir(dir_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a15b2e",
   "metadata": {},
   "source": [
    "## log 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab8bb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 16:47:36 13675053.py [line:16] INFO ------------------------args start----------------------------\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO dir_prj = D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO seed = 42\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO pattern_nums = [-1]\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO thresh = [0, 3000]\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO num_process = 8\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO n_components = 100\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO disable_norm = False\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO disable_ddr = False\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO use_ddr_pca = False\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO use_ddr_kpca = False\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO use_ddr_var = False\n",
      "2025-04-15 16:47:36 13675053.py [line:18] INFO use_ddr_ae = False\n",
      "2025-04-15 16:47:36 13675053.py [line:19] INFO -------------------------args end-----------------------------\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "file_handler = logging.FileHandler(os.path.join(dir_logs, f'base_seed{seed}.log'), mode='w', encoding='utf-8')\n",
    "\n",
    "# 设置日志格式\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(filename)s [line:%(lineno)d] %(levelname)s %(message)s\",\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[console_handler, file_handler],\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "# loging args\n",
    "logging.info('------------------------args start----------------------------')\n",
    "for k, v in vars(args).items():\n",
    "\t\tlogging.info(f'{k} = {v}')\n",
    "logging.info('-------------------------args end-----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58824f0",
   "metadata": {},
   "source": [
    "## 库导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbf9af3-b562-46b5-9c58-e09b93586804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "from data.layout import convert_data_parallel\n",
    "from utils.analysis import ratio_bad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611f84a",
   "metadata": {},
   "source": [
    "## 数据导入与数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823851f3-62b4-44c8-bcdf-cbb46a45f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 16:47:37 3338289207.py [line:50] INFO pattern numbers: ['1', '16', '1601', '23', '26', '2601', '3', '4', '8']\n",
      "2025-04-15 16:47:37 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern1\n",
      "2025-04-15 16:47:37 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern16\n",
      "2025-04-15 16:47:37 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern1601\n",
      "2025-04-15 16:47:37 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern23\n",
      "2025-04-15 16:47:38 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern26\n",
      "2025-04-15 16:47:39 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern2601\n",
      "2025-04-15 16:47:39 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern3\n",
      "2025-04-15 16:47:39 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern4\n",
      "2025-04-15 16:47:40 3338289207.py [line:82] INFO load data from D:/learn_more_from_life/computer/EDA/work/prj/rc_predict/data/convert_data/pattern8\n",
      "2025-04-15 16:47:40 3338289207.py [line:85] INFO raw nums shape: (8821, 1) mean: 177.48588595397348 max: 3389.0 min: 2.0\n",
      "2025-04-15 16:47:40 3338289207.py [line:86] INFO valid nums shape: (8815,) mean: 175.38979013045943 max: 2581.0 min: 2.0\n",
      "2025-04-15 16:47:40 3338289207.py [line:88] INFO x total shape: (8815, 3000, 5) x couple shape: (8815, 3000, 5)\n",
      "2025-04-15 16:47:40 3338289207.py [line:89] INFO x total first 10 samples:\n",
      " [[ 0.00e+00  0.00e+00  0.00e+00  1.50e+02  1.50e+02]\n",
      " [ 0.00e+00  0.00e+00  1.00e+00  1.20e+02  8.00e-02]\n",
      " [ 0.00e+00  1.21e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00 -1.21e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00 -2.42e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00  2.42e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00  3.63e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00 -3.63e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00  4.84e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00 -4.84e-01  1.00e+00  1.00e+02  8.00e-02]]\n",
      "2025-04-15 16:47:40 3338289207.py [line:90] INFO x couple first 10 samples:\n",
      " [[ 0.00e+00  0.00e+00  0.00e+00  1.50e+02  1.50e+02]\n",
      " [ 0.00e+00  0.00e+00  1.00e+00 -1.20e+02 -8.00e-02]\n",
      " [ 0.00e+00  1.21e-01  1.00e+00 -1.00e+02 -8.00e-02]\n",
      " [ 0.00e+00 -1.21e-01  1.00e+00 -1.00e+02 -8.00e-02]\n",
      " [ 0.00e+00  0.00e+00  2.00e+00 -1.50e+02 -1.50e+02]\n",
      " [ 0.00e+00 -2.42e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00  2.42e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00  3.63e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00 -3.63e-01  1.00e+00  1.00e+02  8.00e-02]\n",
      " [ 0.00e+00  4.84e-01  1.00e+00  1.00e+02  8.00e-02]]\n",
      "2025-04-15 16:47:40 3338289207.py [line:92] INFO y total shape: (8815, 2) y couple shape: (8815, 2)\n",
      "2025-04-15 16:47:40 3338289207.py [line:93] INFO y total first 10 samples:\n",
      " [[1242.         9002.078125  ]\n",
      " [1242.           19.02088928]\n",
      " [1242.           19.00154877]\n",
      " [1242.           22.91655159]\n",
      " [1242.         5999.68066406]\n",
      " [1878.         9142.18164062]\n",
      " [1878.           19.81933784]\n",
      " [1878.           19.43289948]\n",
      " [1878.           24.66109657]\n",
      " [1878.         6066.27392578]]\n",
      "2025-04-15 16:47:40 3338289207.py [line:94] INFO y couple first 10 samples:\n",
      " [[1242.         5892.08105469]\n",
      " [1242.           19.02088737]\n",
      " [1242.           19.00154877]\n",
      " [1242.           22.91655159]\n",
      " [1242.         5891.99414062]\n",
      " [1878.         5992.29736328]\n",
      " [1878.           19.81933784]\n",
      " [1878.           19.43289948]\n",
      " [1878.           24.66109657]\n",
      " [1878.         5990.15039062]]\n"
     ]
    }
   ],
   "source": [
    "def data_process_sample(x, y, cnt_max): # 单类样本采样最大限制\n",
    "\tif len(x) > cnt_max:\n",
    "\t\tnew_x = x[:cnt_max]\n",
    "\t\tnew_y = y[:cnt_max]\n",
    "\telse:\n",
    "\t\tnew_x = x\n",
    "\t\tnew_y = y\n",
    "\n",
    "\treturn new_x, new_y\n",
    "\n",
    "def data_process_truncate(x, y, thresh, reserve=False): # 双边 [0 3000] # 矩阵大小截断 筛选可选\n",
    "\tthresh = np.array(thresh, dtype=np.int32)\n",
    "\traw_num = np.array([len(i) for i in x]).reshape(-1, 1)\n",
    "\tvalid_num = np.array([thresh[1] if len(i) > thresh[1] else len(i) for i in x], dtype=np.int32).reshape(-1, 1)\n",
    "\tif reserve:\n",
    "\t\tmask_reserve = np.ones(shape=(len(x),), dtype=np.bool_)\n",
    "\telse:\n",
    "\t\tmask_reserve = (thresh[0] <= raw_num) & (raw_num <= thresh[1])\n",
    "\tsum_reserve = np.sum(mask_reserve, dtype=np.int32)\n",
    "\tnew_x = np.zeros(shape=(sum_reserve, thresh[1], 5), dtype=np.float32)\n",
    "\tnew_y = np.zeros(shape=(sum_reserve, 1), dtype=np.float32)\n",
    "\tindex = 0\n",
    "\tfor i, num in enumerate(valid_num):\n",
    "\t\tnum = num[0]\n",
    "\t\tif mask_reserve[i]:\n",
    "\t\t\tnew_x[index][:num] = x[i][:num]\n",
    "\t\t\tnew_y[index][0] = y[i][0]\n",
    "\t\t\tindex += 1\n",
    "\tvalid_num = valid_num[mask_reserve].reshape(-1, 1)\n",
    "\tnew_y = np.concatenate([valid_num, new_y], axis=1)\n",
    "\n",
    "\treturn new_x, new_y, raw_num\n",
    "\n",
    "\n",
    "x_total = []\n",
    "x_couple = []\n",
    "y_total = []\n",
    "y_couple = []\n",
    "raw_nums = []\n",
    "if len(pattern_nums) == 0:\n",
    "\tlogging.info(\"pattern_nums is empty, please check the config.py\")\n",
    "elif pattern_nums[0] == -1:\n",
    "\tpattern_nums = []\n",
    "\tdir_path = os.path.join(dir_prj, \"data/raw_data\")\n",
    "\tfiles = os.listdir(dir_path)\n",
    "\tfor file in files:\n",
    "\t\tif file.startswith('pattern'):\n",
    "\t\t\tpattern_num = file.split('pattern')[1]\n",
    "\t\t\tpattern_nums.append(pattern_num)\n",
    "\tlogging.info(f'pattern numbers: {pattern_nums}')\n",
    "\n",
    "for pattern_num in pattern_nums:\n",
    "\tdir_load = os.path.join(dir_prj, \"data/convert_data/pattern{}\".format(pattern_num))\n",
    "\tif not os.path.exists(dir_load):\n",
    "\t\t# convert_data(pattern_num)\n",
    "\t\tconvert_data_parallel(dir_prj, pattern_num, num_process=8)\n",
    "\n",
    "\tx_total_ = np.load(os.path.join(dir_load, \"x_total.npy\"), allow_pickle=True)\n",
    "\ty_total_ = np.load(os.path.join(dir_load, \"y_total.npy\")).reshape(-1, 1)\n",
    "\tx_couple_ = np.load(os.path.join(dir_load, \"x_couple.npy\"), allow_pickle=True)\n",
    "\ty_couple_ = np.load(os.path.join(dir_load, \"y_couple.npy\")).reshape(-1, 1)\n",
    "\t# data sample\n",
    "\tx_total_, y_total_ = data_process_sample(x_total_, y_total_, cnt_max=cnt_max)\n",
    "\tx_couple_, y_couple_ = data_process_sample(x_couple_, y_couple_, cnt_max=cnt_max)\n",
    "\t# data truncate\n",
    "\tx_total_, y_total_, total_raw_nums = data_process_truncate(x_total_, y_total_, thresh, reserve=False)\n",
    "\tx_couple_, y_couple_, _ = data_process_truncate(x_couple_, y_couple_, thresh, reserve=False)\n",
    "\n",
    "\t# concatenate data\n",
    "\tif len(x_total) == 0:\n",
    "\t\tx_total = x_total_.copy()\n",
    "\t\tx_couple = x_couple_.copy()\n",
    "\t\ty_total = y_total_.copy()\n",
    "\t\ty_couple = y_couple_.copy()\n",
    "\t\traw_nums = total_raw_nums.copy()\n",
    "\telse:\n",
    "\t\tx_total = np.concatenate([x_total, x_total_], axis=0)\n",
    "\t\tx_couple = np.concatenate([x_couple, x_couple_], axis=0)\n",
    "\t\ty_total = np.concatenate([y_total, y_total_], axis=0)\n",
    "\t\ty_couple = np.concatenate([y_couple, y_couple_], axis=0)\n",
    "\t\traw_nums = np.concatenate([raw_nums, total_raw_nums],  axis=0)\n",
    "\tlogging.info(\"load data from {}\".format(dir_load))\n",
    "\n",
    "valid_num = y_total[:, 0]\n",
    "logging.info(f'raw nums shape: {raw_nums.shape} mean: {np.mean(raw_nums)} max: {np.max(raw_nums)} min: {np.min(raw_nums)}')\n",
    "logging.info(f'valid nums shape: {valid_num.shape} mean: {np.mean(valid_num)} max: {np.max(valid_num)} min: {np.min(valid_num)}')\n",
    "\n",
    "logging.info(f'x total shape: {x_total.shape} x couple shape: {x_couple.shape}')\n",
    "logging.info(f'x total first 10 samples:\\n {x_total[0][:10]}')\n",
    "logging.info(f'x couple first 10 samples:\\n {x_couple[0][:10]}')\n",
    "\n",
    "logging.info(f'y total shape: {y_total.shape} y couple shape: {y_couple.shape}')\n",
    "logging.info(f'y total first 10 samples:\\n {y_total[:10]}')\n",
    "logging.info(f'y couple first 10 samples:\\n {y_couple[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92879dae",
   "metadata": {},
   "source": [
    "## 数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cc341-33f3-46c1-a418-1b2e1dd89ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 17:09:25 3771865223.py [line:6] INFO total x len: 5289 : 1763 : 1763\n",
      "2025-04-15 17:09:25 3771865223.py [line:7] INFO x total train first 10 samples\n",
      " [[ 0.000e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [ 3.200e-01  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [-8.340e-01  0.000e+00  0.000e+00  3.200e-01  1.100e+02]\n",
      " [ 1.154e+00  0.000e+00  0.000e+00  3.200e-01  1.000e+02]\n",
      " [-1.668e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [ 1.988e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [-1.988e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [ 2.308e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [-2.822e+00  0.000e+00  0.000e+00  3.200e-01  1.000e+02]\n",
      " [ 3.142e+00  0.000e+00  0.000e+00  3.200e-01  1.000e+02]]\n",
      "2025-04-15 17:09:25 3771865223.py [line:8] INFO y total train first 10 samples\n",
      " [[226.           5.06360579]\n",
      " [190.           5.18423319]\n",
      " [ 15.           8.85817242]\n",
      " [ 94.           5.1069932 ]\n",
      " [ 15.           3.67533803]\n",
      " [277.          18.91185188]\n",
      " [ 75.          18.11878967]\n",
      " [163.          10.71372509]\n",
      " [259.          11.33617783]\n",
      " [  2.         442.63696289]]\n",
      "2025-04-15 17:09:25 3771865223.py [line:12] INFO couple x len: 5289 : 1763 : 1763\n",
      "2025-04-15 17:09:25 3771865223.py [line:13] INFO x couple train first 10 samples\n",
      " [[ 0.000e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [-8.340e-01  0.000e+00  0.000e+00 -3.200e-01 -1.100e+02]\n",
      " [-1.668e+00  0.000e+00  0.000e+00 -4.800e-02 -8.000e+01]\n",
      " [ 3.200e-01  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [ 1.154e+00  0.000e+00  0.000e+00  3.200e-01  1.000e+02]\n",
      " [ 1.988e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [-1.988e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [ 2.308e+00  0.000e+00  0.000e+00  4.800e-02  8.000e+01]\n",
      " [-2.822e+00  0.000e+00  0.000e+00  3.200e-01  1.000e+02]\n",
      " [ 3.142e+00  0.000e+00  0.000e+00  3.200e-01  1.000e+02]]\n",
      "2025-04-15 17:09:25 3771865223.py [line:14] INFO y couple train first 10 samples\n",
      " [[2.26000000e+02 4.10106003e-01]\n",
      " [1.90000000e+02 7.97078013e-01]\n",
      " [2.60000000e+01 2.32115000e-01]\n",
      " [9.40000000e+01 8.28780010e-02]\n",
      " [2.60000000e+01 2.89745003e-01]\n",
      " [2.77000000e+02 1.89118519e+01]\n",
      " [1.48000000e+02 6.76210999e-01]\n",
      " [1.63000000e+02 3.71684015e-01]\n",
      " [2.59000000e+02 1.49945104e+00]\n",
      " [2.00000000e+00 1.05578005e+00]]\n"
     ]
    }
   ],
   "source": [
    "# data split 6:2:2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_total_train, x_total_valid_test, y_total_train, y_total_valid_test = train_test_split(x_total, y_total, test_size=0.4, random_state=seed, shuffle=True)\n",
    "x_total_valid, x_total_test, y_total_valid, y_total_test = train_test_split(x_total_valid_test, y_total_valid_test, test_size=0.5, random_state=seed, shuffle=True)\n",
    "logging.info(f'total x len: {len(x_total_train)} : {len(x_total_valid)} : {len(x_total_test)}')\n",
    "logging.info(f'x total train first 10 samples\\n {x_total_train[0][:10]}')\n",
    "logging.info(f'y total train first 10 samples\\n {y_total_train[:10]}')\n",
    "\n",
    "x_couple_train, x_couple_valid_test, y_couple_train, y_couple_valid_test = train_test_split(x_couple, y_couple, test_size=0.4, random_state=seed, shuffle=True)\n",
    "x_couple_valid, x_couple_test, y_couple_valid, y_couple_test = train_test_split(x_couple_valid_test, y_couple_valid_test, test_size=0.5, random_state=seed, shuffle=True)\n",
    "logging.info(f'couple x len: {len(x_couple_train)} : {len(x_couple_valid)} : {len(x_couple_test)}')\n",
    "logging.info(f'x couple train first 10 samples\\n {x_couple_train[0][:10]}')\n",
    "logging.info(f'y couple train first 10 samples\\n {y_couple_train[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82806e19",
   "metadata": {},
   "source": [
    "## 数据预处理(归一化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f08ea-6867-4e26-8bc0-b751a95df67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs shape:  (15867000,) min:  -0.6683333516120911 max:  0.530239999294281 mean:  -1.6714792412469852e-05\n",
      "ys shape:  (15867000,) min:  -0.6684666275978088 max:  0.5333333611488342 mean:  -0.00174169735776085\n",
      "zs shape:  (15867000,) min:  -0.00031999999191612005 max:  0.00031999999191612005 mean:  -3.917564658076909e-07\n",
      "widths shape:  (15867000,) min:  -0.9999866485595703 max:  1.0533332824707031 mean:  -0.017883587428630467\n",
      "heights shape:  (15867000,) min:  -0.9999333620071411 max:  1.007200002670288 mean:  -0.03578649050129559\n",
      "window size:  150\n"
     ]
    }
   ],
   "source": [
    "# min max \n",
    "from data.preprocess import data_process\n",
    "\n",
    "\n",
    "if DISABLE_NORM:\n",
    "\tx_total_train_norm_flat = x_total_train.reshape(len(x_total_train), -1)\n",
    "\tx_total_valid_norm_flat = x_total_valid.reshape(len(x_total_valid), -1)\n",
    "\tx_total_test_norm_flat = x_total_test.reshape(len(x_total_test), -1)\n",
    "\tx_couple_train_norm_flat = x_couple_train.reshape(len(x_couple_train), -1)\n",
    "\tx_couple_valid_norm_flat = x_couple_valid.reshape(len(x_couple_valid), -1)\n",
    "\tx_couple_test_norm_flat = x_couple_test.reshape(len(x_couple_test), -1)\n",
    "else:\n",
    "\t# 数据归一化\n",
    "\tx_total_train_norm = data_process(x_total_train, y_total_train)\n",
    "\tx_total_valid_norm = data_process(x_total_valid, y_total_valid)\n",
    "\tx_total_test_norm = data_process(x_total_test, y_total_test)\n",
    "\tx_couple_train_norm = data_process(x_couple_train, y_couple_train)\n",
    "\tx_couple_valid_norm = data_process(x_couple_valid, y_couple_valid)\n",
    "\tx_couple_test_norm = data_process(x_couple_test, y_couple_test)\n",
    "\n",
    "\t## 数据扁平化\n",
    "\tx_total_train_norm_flat = x_total_train_norm.reshape(len(x_total_train_norm), -1)\n",
    "\tx_total_valid_norm_flat = x_total_valid_norm.reshape(len(x_total_valid_norm), -1)\n",
    "\tx_total_test_norm_flat = x_total_test_norm.reshape(len(x_total_test_norm), -1)\n",
    "\tx_couple_train_norm_flat = x_couple_train_norm.reshape(len(x_couple_train_norm), -1)\n",
    "\tx_couple_valid_norm_flat = x_couple_valid_norm.reshape(len(x_couple_valid_norm), -1)\n",
    "\tx_couple_test_norm_flat = x_couple_test_norm.reshape(len(x_couple_test_norm), -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0c64aa",
   "metadata": {},
   "source": [
    "## 降维处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a523d",
   "metadata": {},
   "source": [
    "#### 传统降维方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becaa495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始维度 10000维\n",
    "from sklearn import decomposition\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2\n",
    "\n",
    "\n",
    "if USE_DDR:\t\n",
    "\tif USE_DDR_PCA:\n",
    "\t\tpca_total = decomposition.PCA(n_components=n_components, copy=True, whiten=True)\n",
    "\t\tpca_total.fit(x_total_train_norm_flat)\n",
    "\t\tpca_couple = decomposition.PCA(n_components=n_components, copy=True, whiten=True)\n",
    "\t\tpca_couple.fit(x_couple_train_norm_flat)\n",
    "\t\tddr_total = pca_total\n",
    "\t\tddr_couple = pca_couple\n",
    "\telif USE_DDR_KPCA:\n",
    "\t\tkpca_total = decomposition.KernelPCA(n_components=n_components, kernel='rbf')\n",
    "\t\tkpca_total.fit(x_total_train_norm_flat)\n",
    "\t\tkpca_couple = decomposition.KernelPCA(n_components=n_components, kernel='rbf')\n",
    "\t\tkpca_couple.fit(x_couple_train_norm_flat)\n",
    "\t\tddr_total = kpca_total\n",
    "\t\tddr_couple = kpca_couple\n",
    "\telif USE_DDR_VAR:\n",
    "\t\tvar_total = VarianceThreshold(threshold=0.5)\n",
    "\t\tvar_total.fit(x_total_train_norm_flat)\n",
    "\t\tvar_couple = VarianceThreshold(threshold=0.5)\n",
    "\t\tvar_couple.fit(x_couple_train_norm_flat)\n",
    "\t\tddr_total = var_total\n",
    "\t\tddr_couple = var_couple\n",
    "\telse:\n",
    "\t\tddr_total = None\n",
    "\t\tddr_couple = None\n",
    "else:\n",
    "\tddr_total = None\n",
    "\tddr_couple = None\n",
    "\n",
    "# transform\n",
    "if ddr_total is not None and ddr_couple is not None:\n",
    "\tx_total_train_norm_flat_ddr = ddr_total.transform(x_total_train_norm_flat)\n",
    "\tx_total_valid_norm_flat_ddr = ddr_total.transform(x_total_valid_norm_flat)\n",
    "\tx_total_test_norm_flat_ddr = ddr_total.transform(x_total_test_norm_flat)\n",
    "\tx_couple_train_norm_flat_ddr = ddr_couple.transform(x_couple_train_norm_flat)\n",
    "\tx_couple_valid_norm_flat_ddr = ddr_couple.transform(x_couple_valid_norm_flat)\n",
    "\tx_couple_test_norm_flat_ddr = ddr_couple.transform(x_couple_test_norm_flat)\n",
    "\n",
    "# plot\n",
    "# ratio = ddr_total.explained_variance_ratio_\n",
    "# cum_ratio = np.cumsum(ratio)\n",
    "# logging.info(f'total cum ratio {cum_ratio}')\n",
    "# plt.plot(range(n_components), cum_ratio)\n",
    "# plt.show()\n",
    "# logging.info(f'total sum ratio {np.sum(ratio)}')\n",
    "\n",
    "# ratio = ddr_couple.explained_variance_ratio_\n",
    "# cum_ratio = np.cumsum(ratio)\n",
    "# logging.info(f'couple cum ratio {cum_ratio}')\n",
    "# plt.plot(range(n_components), cum_ratio)\n",
    "# plt.show()\n",
    "# logging.info(f'couple sum ratio {np.sum(ratio)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a93d9",
   "metadata": {},
   "source": [
    "#### 新型降维方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2bab0",
   "metadata": {},
   "source": [
    "##### 自编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27405ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_DDR and USE_DDR_AE:\n",
    "\timport tensorflow as tf\n",
    "\tfrom tensorflow import keras\n",
    "\n",
    "\t# encoding dim 100\n",
    "\tencoding_dim = n_components\n",
    "\n",
    "\t# input dim 10000\n",
    "\tinput_dim = x_total_train_norm_flat.shape[1]\n",
    "\tinput_layer = keras.layers.Input(shape=(input_dim,))\n",
    "\t# encoding layer\n",
    "\tencoded = keras.layers.Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\t# decoding layer\n",
    "\tdecoded = keras.layers.Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "\t# autoencoder\n",
    "\tautoencoder = keras.models.Model(input_layer, decoded)\n",
    "\t# encoder\n",
    "\tencoder = keras.models.Model(input_layer, encoded)\n",
    "\t# decoder\n",
    "\tencoded_input = keras.layers.Input(shape=(encoding_dim,))\n",
    "\tdecoder_layer = autoencoder.layers[-1]\n",
    "\tdecoder = keras.models.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "\t# compile\n",
    "\tautoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\t# fit\n",
    "\tautoencoder.fit(x_total_train_norm_flat, x_total_train_norm_flat,\n",
    "\t\t\t\t\t\t\t\t\tepochs=100,\n",
    "\t\t\t\t\t\t\t\t\tbatch_size=32,\n",
    "\t\t\t\t\t\t\t\t\tshuffle=True,\n",
    "\t\t\t\t\t\t\t\t\tvalidation_data=(x_total_valid_norm_flat, x_total_valid_norm_flat))\n",
    "\n",
    "\t# history\n",
    "\thistory = autoencoder.history.history\n",
    "\tplt.plot(history['loss'], label='train')\n",
    "\tplt.plot(history['val_loss'], label='valid')\n",
    "\tplt.legend()\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.show()\n",
    "\n",
    "\t# encode data\n",
    "\tx_total_train_norm_flat_ddr = encoder.predict(x_total_train_norm_flat)\n",
    "\tx_total_valid_norm_flat_ddr = encoder.predict(x_total_valid_norm_flat)\n",
    "\tx_total_test_norm_flat_ddr = encoder.predict(x_total_test_norm_flat)\n",
    "\tx_couple_train_norm_flat_ddr = encoder.predict(x_couple_train_norm_flat)\n",
    "\tx_couple_valid_norm_flat_ddr = encoder.predict(x_couple_valid_norm_flat)\n",
    "\tx_couple_test_norm_flat_ddr = encoder.predict(x_couple_test_norm_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574a137",
   "metadata": {},
   "source": [
    "### 禁用降维方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISABLE_DDR:\n",
    "\tx_total_train_norm_flat_ddr = x_total_train_norm_flat\n",
    "\tx_total_valid_norm_flat_ddr = x_total_valid_norm_flat\n",
    "\tx_total_test_norm_flat_ddr = x_total_test_norm_flat\n",
    "\tx_couple_train_norm_flat_ddr = x_couple_train_norm_flat\n",
    "\tx_couple_valid_norm_flat_ddr = x_couple_valid_norm_flat\n",
    "\tx_couple_test_norm_flat_ddr = x_couple_test_norm_flat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d9ff1",
   "metadata": {},
   "source": [
    "## 命名简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aaac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total \n",
    "xt_train = x_total_train_norm_flat_ddr\n",
    "xt_valid = x_total_valid_norm_flat_ddr\n",
    "xt_test = x_total_test_norm_flat_ddr\n",
    "yt_train = y_total_train[:, 1].reshape(-1, 1)\n",
    "yt_valid = y_total_valid[:, 1].reshape(-1, 1)\n",
    "yt_test = y_total_test[:, 1].reshape(-1, 1)\n",
    "\n",
    "# couple\n",
    "xc_train = x_couple_train_norm_flat_ddr\n",
    "xc_valid = x_couple_valid_norm_flat_ddr\n",
    "xc_test = x_couple_test_norm_flat_ddr\n",
    "yc_train = y_couple_train[:, 1].reshape(-1, 1)\n",
    "yc_valid = y_couple_valid[:, 1].reshape(-1, 1)\n",
    "yc_test = y_couple_test[:, 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469b93d",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35226a33",
   "metadata": {},
   "source": [
    "### 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc7d03-b048-4937-80ba-51c62861b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from utils.analysis import model_analysis\n",
    "\n",
    "\n",
    "# total\n",
    "logging.info('--------------------------------total------------------------------')\n",
    "lr_t = LinearRegression()\n",
    "lr_t.fit(xt_train, yt_train.ravel())\n",
    "dict_total = model_analysis(lr_t, xt_train, yt_train, xt_valid, yt_valid, xt_test, yt_test, 'linear reg')\n",
    "logging.info(f'total model analysis:\\n {dict_total}')\n",
    "results_total = pd.Series(dict_total).to_frame().T\n",
    "\n",
    "# couple\n",
    "logging.info('--------------------------------couple------------------------------')\n",
    "lr_c = LinearRegression()\n",
    "lr_c.fit(xc_train, yc_train.ravel())\n",
    "dict_couple = model_analysis(lr_c, xc_train, yc_train, xc_valid, yc_valid, xc_test, yc_test, 'linear reg')\n",
    "logging.info(f'couple model analysis:\\n {dict_couple}')\n",
    "results_couple = pd.Series(dict_couple).to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85016a7",
   "metadata": {},
   "source": [
    "### 支持向量机回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f4997-0d6c-4b57-b8e0-b58e8b89e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# total\n",
    "logging.info('--------------------------------total------------------------------')\n",
    "# linear svr\n",
    "lr_svf_t = SVR(kernel='linear', max_iter=1000)\n",
    "lr_svf_t.fit(xt_train, yt_train.ravel())\n",
    "dict_total = model_analysis(lr_svf_t, xt_train, yt_train, xt_valid, yt_valid, xt_test, yt_test, 'linear svr')\n",
    "logging.info(f'total model analysis:\\n {dict_total}')\n",
    "results_total = pd.concat([results_total, pd.Series(dict_total).to_frame().T], axis=0)\n",
    "# poly svr\n",
    "poly_svf_t = SVR(kernel='poly', max_iter=1000)\n",
    "poly_svf_t.fit(xt_train, yt_train.ravel())\n",
    "dict_total = model_analysis(poly_svf_t, xt_train, yt_train, xt_valid, yt_valid, xt_test, yt_test, 'poly svr')\n",
    "logging.info(f'total model analysis:\\n {dict_total}')\n",
    "results_total = pd.concat([results_total, pd.Series(dict_total).to_frame().T], axis=0)\n",
    "# rbf svr\n",
    "rbf_svf_t = SVR(kernel='rbf', max_iter=1000)\n",
    "rbf_svf_t.fit(xt_train, yt_train.ravel())\n",
    "dict_total = model_analysis(rbf_svf_t, xt_train, yt_train, xt_valid, yt_valid, xt_test, yt_test, 'rbf svr')\n",
    "logging.info(f'total model analysis:\\n {dict_total}')\n",
    "results_total = pd.concat([results_total, pd.Series(dict_total).to_frame().T], axis=0)\n",
    "\n",
    "# couple\n",
    "logging.info('--------------------------------couple------------------------------')\n",
    "# linear svr\n",
    "lr_svf_c = SVR(kernel='linear', max_iter=1000)\n",
    "lr_svf_c.fit(xc_train, yc_train.ravel())\n",
    "dict_couple = model_analysis(lr_svf_c, xc_train, yc_train, xc_valid, yc_valid, xc_test, yc_test, 'linear svr')\n",
    "logging.info(f'couple model analysis:\\n {dict_couple}')\n",
    "results_couple = pd.concat([results_couple, pd.Series(dict_couple).to_frame().T], axis=0)\n",
    "# poly svr\n",
    "poly_svf_c = SVR(kernel='poly', max_iter=1000)\n",
    "poly_svf_c.fit(xc_train, yc_train.ravel())\n",
    "dict_couple = model_analysis(poly_svf_c, xc_train, yc_train, xc_valid, yc_valid, xc_test, yc_test, 'poly svr')\n",
    "logging.info(f'couple model analysis:\\n {dict_couple}')\n",
    "results_couple = pd.concat([results_couple, pd.Series(dict_couple).to_frame().T], axis=0)\n",
    "# rbf svr\n",
    "rbf_svf_c = SVR(kernel='rbf', max_iter=1000)\n",
    "rbf_svf_c.fit(xc_train, yc_train.ravel())\n",
    "dict_couple = model_analysis(rbf_svf_c, xc_train, yc_train, xc_valid, yc_valid, xc_test, yc_test, 'rbf svr')\n",
    "logging.info(f'couple model analysis:\\n {dict_couple}')\n",
    "results_couple = pd.concat([results_couple, pd.Series(dict_couple).to_frame().T], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558ac84",
   "metadata": {},
   "source": [
    "### K近邻回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271249a4-3b5a-49e4-8d27-0ff459682c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# total \n",
    "logging.info('--------------------------------total------------------------------')\n",
    "# uniform knn\n",
    "uni_knn_t = KNeighborsRegressor(n_neighbors=5, weights='uniform')\n",
    "uni_knn_t.fit(xt_train, yt_train.ravel())\n",
    "dict_total = model_analysis(uni_knn_t, xt_train, yt_train, xt_valid, yt_valid, xt_test, yt_test, 'uniform knn')\n",
    "logging.info(f'total model analysis:\\n {dict_total}')\n",
    "results_total = pd.concat([results_total, pd.Series(dict_total).to_frame().T], axis=0)\n",
    "# distance knn\n",
    "dis_knn_t = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "dis_knn_t.fit(xt_train, yt_train.ravel())\n",
    "dict_total = model_analysis(dis_knn_t, xt_train, yt_train, xt_valid, yt_valid, xt_test, yt_test, 'distance knn')\n",
    "logging.info(f'total model analysis:\\n {dict_total}')\n",
    "results_total = pd.concat([results_total, pd.Series(dict_total).to_frame().T], axis=0)\n",
    "\n",
    "# couple\n",
    "logging.info('--------------------------------couple------------------------------')\n",
    "# uniform knn\n",
    "uni_knn_c = KNeighborsRegressor(n_neighbors=5, weights='uniform')\n",
    "uni_knn_c.fit(xc_train, yc_train.ravel())\n",
    "dict_couple = model_analysis(uni_knn_c, xc_train, yc_train, xc_valid, yc_valid, xc_test, yc_test, 'uniform knn')\n",
    "logging.info(f'couple model analysis:\\n {dict_couple}')\n",
    "results_couple = pd.concat([results_couple, pd.Series(dict_couple).to_frame().T], axis=0)\n",
    "# distance knn\n",
    "dis_knn_c = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "dis_knn_c.fit(xc_train, yc_train.ravel())\n",
    "dict_couple = model_analysis(dis_knn_c, xc_train, yc_train, xc_valid, yc_valid, xc_test, yc_test, 'distance knn')\n",
    "logging.info(f'couple model analysis:\\n {dict_couple}')\n",
    "results_couple = pd.concat([results_couple, pd.Series(dict_couple).to_frame().T], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9449a06",
   "metadata": {},
   "source": [
    "### 回归树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# total\n",
    "logging.info('--------------------------------total------------------------------')\n",
    "dtr_t = DecisionTreeRegressor()\n",
    "dtr_t.fit(xt_train, yt_train.ravel())\n",
    "dict_total = model_analysis(dtr_t, xt_train, yt_train, xt_valid, yt_valid, xt_test, yt_test, 'decision tree total')\n",
    "logging.info(f'total model analysis:\\n {dict_total}')\n",
    "results_total = pd.concat([results_total, pd.Series(dict_total).to_frame().T], axis=0)\n",
    "\n",
    "# couple\n",
    "logging.info('--------------------------------couple------------------------------')\n",
    "dtr_c = DecisionTreeRegressor()\n",
    "dtr_c.fit(xc_train, yc_train.ravel())\n",
    "dict_couple = model_analysis(dtr_c, xc_train, yc_train, xc_valid, yc_valid, xc_test, yc_test, 'decision tree couple')\n",
    "logging.info(f'couple model analysis:\\n {dict_couple}')\n",
    "results_couple = pd.concat([results_couple, pd.Series(dict_couple).to_frame().T], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93804e6",
   "metadata": {},
   "source": [
    "### 集成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9351d3",
   "metadata": {},
   "source": [
    "#### 基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# total\n",
    "logging.info('--------------------------------total------------------------------')\n",
    "# random forest\n",
    "rfr_t = RandomForestRegressor()\n",
    "rfr_t.fit(xt_train, yt_train.ravel())\n",
    "dict_total = model_analysis(rfr_t, xt_train, yt_train, xt_valid, yt_valid, xt_test, yt_test, 'random forest')\n",
    "logging.info(f'total model analysis:\\n {dict_total}')\n",
    "results_total = pd.concat([results_total, pd.Series(dict_total).to_frame().T], axis=0)\n",
    "\n",
    "# couple\n",
    "logging.info('--------------------------------couple------------------------------')\n",
    "# random forest\n",
    "rfr_c = RandomForestRegressor()\n",
    "rfr_c.fit(xc_train, yc_train.ravel())\n",
    "dict_couple = model_analysis(rfr_c, xc_train, yc_train, xc_valid, yc_valid, xc_test, yc_test, 'random forest')\n",
    "logging.info(f'couple model analysis:\\n {dict_couple}')\n",
    "results_couple = pd.concat([results_couple, pd.Series(dict_couple).to_frame().T], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cc5b4",
   "metadata": {},
   "source": [
    "## 结果存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results_total and results_couple to csv\n",
    "results_total.to_csv(os.path.join(dir_results, \"base_total.csv\"), index=False)\n",
    "results_couple.to_csv(os.path.join(dir_results, \"base_couple.csv\"), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
